<!DOCTYPE html>
<html lang=en>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Towards spirit stream</title>
    <link rel="stylesheet" href="main.css">
    <link rel="shortcut icon" href="favicon.ico">
</head>

<body>
    <main>
        <nav><a href='index.html'>Entrance</a><a href="#top">Top</a></nav>
        <article>
            <div id="top"></div>
            <p class="post-date">Created <time datetime="2024-01-23T19:19:31+08:00">2024 01 23</time></p>

            <p>
                I have been wondering about information distribution, feeling inefficient.<br>
                This page reflects on how to build a seemless, integrated information structure for it, and <a href="https://github.com/lorinbaum/spiritstream">this repo</a> is where it's built.
            </p>
            
            <h1>Towards spirit stream</h1>
            
            <nav class="toc"></nav>

            <h2>More refined</h2>

            <h3>Spirit Stream</h3>
            <p> 
                When I follow curiosity, leaning into my wonder about computer and internet, I sense dissolution: The edges of my body fade and I float through the associations between all possible spaces. Into the space, through trees, stories, videogames, temples, beauty, destruction. I see my questions answered, not definitively, but as completely as the collective mind can. I sense connection, trusting and deep. I sense the conflicts in the world as internal, not as foggy, distant pain. There are no external barriers to my being and I stream into others to see exactly what they mean. And in my action, the structure of the world, not merely my individual life, is reflected.<br>
                Returning to my body, I can't help but wonder what the fuck this is: Me, stopping with my fingertips, not being able to walk through walls, facing the endless world in mist asking hello with no answer.
            </p>
            <figure>
                <img src="creative-destruction-detail-3.jpg" alt="Floating head, slightly tilted. Partly shaded, mask-like. Reminiscent of a skull. Dark background and dark lines across the white head, partly messy, decorative and minimally defining facial features. Closer eye is white, farther eye is black. Red-magenta lines overlay the skull, partly straight and splitting the image, partly squiggly."/>
                <figcaption>Spirit of curiosity</figcaption>
            </figure>
            <blockquote>
                i can see the hive mind on the horizon.<br>
                there are hammers, sculptors, hammer blows and sculptures.<br>
                grouped and isolated<br>
                places to stay.<br>
                <br>
                like gazing into a painting, being guided through the impression<br>
                coming along to find a question asked at myself, seeing it unfold and building a response
            </blockquote>
            <p>
                There seems to be a structure behind notes, memes, essays, books, stories, exhibitions, spaces, products, worlds. They consists of simple patterns in the mind and this may be their process:
            </p>
            <blockquote>
                <p>
                    Sense, explore, parse circling patterns from<br>
                    chaotic and far-reaching,<br>
                    through filtered and coherent knowledge,<br>
                    to linearized, actionable and accessible stories.
                </p>
                <p>
                    Express in sound, body,<br>
                    writing, graphs, images, products,<br>
                    and any tools to build them,<br>
                    in process,<br>
                    from memory.
                </p>
                <p>
                    Share in truth,<br>
                    to test, be surprised, dance, reproduce, join the cutting edge, offer, cohere, support, punish,<br>
                    into common languages per context,<br>
                    into scopes of recipients,<br>
                    under optional conditions.
                </p>
                <p>
                    Where I am,<br>
                    When I am.
                </p>
            </blockquote>
            <p>If the process can be reflected in the machine, the patterns and me with them can seamlessly enter the machine and the machine's properties:</p>
            <blockquote>
                <p>
                    Executors of machine code within instruction sets,<br>
                    of functions, programs, function approximators compiled from many languages,<br>
                    from and to memory.
                </p>
                <p>
                    Store and retrieve anything, persistently, quickly
                </p>
                <p>
                    Express in any electric actuator,<br>
                    speaker, display, motor.<br>
                    Receiving from any electric sensor,<br>
                    keyboard, mouse, camera, microphone
                </p>
                <p>
                    Exchange anything at up to ~storage speeds,<br>
                    through ports, through fundamentally unreliable, insecure connections,<br>
                    to any available address,<br>
                    made reliable, secure through protocol and application server
                </p>
            </blockquote>
            <p>...become my own. The spiritstream aims to be the passage into the machine.</p>
            
            
            <h3>How to merge?</h3>
            <p>
                Since I construct meaning from the individual, I view all higher structures of power (groups, communes, cities, states, religions) as a service to the individual. This is how they are justified and how they ought to be kept in check. When merging with the machine, build the passage from the individual upwards to avoid top-down dominance.
            </p>
            <p>
                Build a machine, make it work. Put the world into it, authenticate to make extension to other entities optional and not excessive. Authenticate through the network into more machines.
            </p>
            <p>
                Is there a throughput problem and must I build the neural interface? I suspect not, as sometimes simple words or images speak so loudly and clearly, throwing open the doors to the world with their precision and closeness. If the interface becomes seamless, reflective of the user, and the spirits of computer and internet reveal themselves, there is no difference between the machine and the body. When I can speak with clarity and my computer extension answers with clarity, we merge.
            </p>
            <p>
                Create, reuse, organize and share arbitrary symbols in 3D space, which is the most dimensions I can understand and use intuitively.<br>
                Remember in a continuous stream of actions to provide a seamless safety net and past data to learn from. It encourages revisiting instead of starting anew, improving quality, and allowing fearless, even reckless editing.
            </p>
            <p>
                Synchronizes with untrusted remote servers. Uses end-to-end encryption for non-public data. Public data is available in the web view.
            </p>
            <p>
                Fundamentally, the spiritstream becomes the primary interface to the computer, the operating system. Motivation for depth and vertical integration is <i>meet the computer and let higher structures fall into their place</i>. No need to go into hardware until software is insanely great.<br>
                Initially, it's a desktop client using python, OpenGL and GLFW to refine abstraction before setting them into C and becoming standalone.
            </p>
            <p>
                To discover and be discovered, search engines, LLM pretraining or dynamic research through an LLM seem sufficient. There is limited upside to being connected to <i>everyone</i> immediately, as on X. A filter of some sort, like the necessity for direct reference by someone or a recommendation algorithm that understand me, seems useful.<br>
                Algorithms and humans have equal capability when interacting with the spirit stream to provide seamless value: A local or remote server handles all file modifications, while a trusted client is the interface.
            </p>
            
            <h3>Current process for publishing:</h3>
            <p>
                Writing in pure html, css, javascript: VS Code,
                prerendering to static sites locally (table of contents): node.js<br>
                keeping history in a git repository,<br>
                Synchronizing with remote server over SFTP using python paramiko: Hetzner VPS: OpenSSH, nginx (HTTP, HTTPS) <br>
                Discoverable through Cloudlfare DNS.
            </p>
            
            <h2>Less refined</h2>
            
            <ul>
                <li>Font engine renders vector outlines into images on demand for highly flexible placement by the editor.</li>
                <li>Editor places symbols into any language to manifest patterns. It can have arbitrarily many tools to make manipulation of symbols and symbol groups easier including for special cases like calendars, messaging, todo-lists. The editor can display relationships in at most 3 dimensions because that's what I can handle. Higher dimensions are handled by links. When information is linearized, a hierarchy of boxes like HTML seems appropriate.</li>
                <li>Authentication / encryption allows privacy to be the default and makes the spiritstream appropriate for more complete information.</li>
                <li>Server (HTTP, HTTPS,...) manages permission and makes content public</li>
                <li>...server-client model + API for machines, AI integration, downloading, streaming, media,...</li>
                <li>...simplfy, implemented in C, compile to embedded...</li>
                <li>...Introspection for access logs and performance review...</li>
                <li>...robots...</li>
            </ul>

            <p>Client:</p>
            <ul>
                <li>WYSIWYG editor</li>
                <li>history</li>
            </ul>
            <p>Server</p>
            <ul>
                <li>authenticate</li>
                <li>send/receive(save) files</li>
                <li>encrypt + decrypt files</li>
                <li>synchronize with other servers</li>
            </ul>

            <h3>Editor</h3>
            <p>
                Text boxes: provide interface basic like cursor(idx)->None, coordinates of text boxes, cursor positions, line wraps. It takes the dimensions of the box and text + styling information, then displays it.
                Subblocks are just different in styling. like heading, blockquote. then some have special functions, like code blocks (highlighting, copying, running) and links (open). image blocks are links that display the content of where they link to - each glyph is a link like that. Embed/transclude vs hyperlink. GO - SHOW

                class viewport or just VIEW(file, x, y, width, height). It finds boxes that intersect the viewport box and within those, renders the things that would be visible. scrolling is just moving up / down with the window. render all quads, then use transformation matrix to display them. scrolling = changing transformation matrix. What is the entry point of the file? entry point should be a block as well. it will guarantee that whatever is in the block is displayed on loading. actually, just show where I last left off. styling includes dynamically creating the thing, like html does based on resolution and so on. later, in 3D context, restricting to basic 1D will be practical. like pressing E to interact with the text puts it fullscreen, so I can comfortably read it. Then it behaves like a website. or there is some fundamental scaling and .
                No. linearized text is in narrow columns anyway for readability. size does not matter. I can click on it to zoom in. it will display the text on my screen. multiple columns if possible, or just not. it will be my responbility to make it work. the ez access version is traditional html anyway. And in 3D its impossible to make it work for different media. I make it work for me. Though anybody can click on it like in cyberpunk to read the text and perceive the formatting otherwise. from some distance. its easy conversion to html anyway so viewing is giga ez. what is viewed? what do I click on when I click and it has multiple layers? I click on the largest group. in that view, links work to help me see other stuff as well.
            </p>

            <h3>Log</h3>

            <p>
                Continuously store individual actions. Data is not included but referenced to improve performance. Should be like a piece chain but with a way to reduce the number of pieces or group into areas, the history of which can be traversed idependently?<br>
                Hash additions / larger sections for integrity checks.<br>
                Self optimizing cache for past states.
            </p>

            <div class="codehilite"><pre><code>file structure:

The log can store write, erase, seek (time/file+cursor) and meta (non-essential)

Upon loading, the log checks integrity and adjusts to any unrecorded changes:
- get latest view according to log file
- get difference to home files
- log events to catch up with home files.

class Log:
    def __init__(self, filepath):
        """Initialize log with the given file path."""

    def write(self, text, cursor=None, author=None):
        """Insert text at cursor."""

    def erase(self, count, cursor=None, author=None):
        """Remove count characters at cursor."""

    def save(self):
        """Save changes to the log."""
    
    def view(self, date):
        """Return the state as of the given date, without altering current state."""
    
    # internal methods
    def _seek(self, position):
        """Record a seek event if cursor position changes."""

    def _meta(self, **kwargs):
        """Record a meta event storing keys and values like user:alice or comment:"hamedi is coming for you" """

    def _elapsed(self, seconds):
        """Record elapsed time since last event."""</code></pre></div>

            <h3>File system</h3>
            <p>Sequences of bytes. Higher dimensions are represented through pointers/links. No hierarchy, just places pointing to other places. Start at entry point or last position. Search by link name(s) that must be associated with a given search target. Choose whether to consider each link bidirectional or not.<br>
            Example: "page, hamedi" searches for all content that is associated with "page" and "hamedi", where "page" may not be more than an empty link target to enable differentiation in searches like this, like tags.</p>
            <p>Pointer may be GO or SHOW, being displayed either as a "door" to the data or embedding the data in it's place.</p>
            <p>Delete, copy, rename are meta: they don't modify the link but the data it points to. Delete is the same as removing all references to a piece of data. Garbage collect to free memory again.</p>
            <p>Messages are data linked to sender/recipient automatically received or that I actively send out.</p>
            <p>Privacy map determines which areas of data require authentication / decryption</p>

            <h3>other</h3>

            <h4>OS</h4>
            <details>
                <summary><a href="https://wiki.osdev.org/BareBones">OSDev</a> Barebones and preliminary notes</summary>
                <p><a href="https://wiki.osdev.org/Expanded_Main_Page">OSDev.org</a>. The OS is first developed for only one target machine. Relevant components:</p>
                <ul>
                    <li>Asus Z270E mainboard</li>
                    <li>Intel 7700k processor</li>
                    <!-- <li>Nvidia GTX 1080ti</li> -->
                    <li>SATA HDDs and SSD, M.2 SSD</li>
                    <li>3860x2160 monitor via display port</li>
                    <li>USB mouse and keyboard</li>
                    <li>Headphones via line out</li>
                </ul>
                <ul>
                    <li><a href="#bare-bones">Bare Bones</a> reinterprets the <a href="https://wiki.osdev.org/Bare_Bones">Bare Bones tutorial</a> on OSDev.org for my usecase, shortening some and expanding on other concepts that seem fundamentally important.</li>
                </ul>
                <!--
                GRUB magic software but needs glue code and set up stack for kernel (C)
                explain stack
                GRUB loads me into 32 bit protected mode, sets up a VGA buffer.
                The kernel uses the buffer to write text. summarized
    
                linker manages the situation where multiple files are needed for a program to run.
    
                creating an iso image with xorriso.
                loading it with qemu
    
                paging is coping with limited 32 bit address space. long mode solves this
                instruction set is HUGE. 
    
                getting graphics working may be hard. nvidia driver is proprietary, can only try and port the linux version of their driver. intel integrated graphics driver is open source.
                otherwise use VGA / VESA but has limited resolution/capability/efficiency. Always runs on CPU, but can use integrated graphics. intel integrated graphics has a completely open driver.
                
                my own bootloader: https://wiki.osdev.org/Rolling_Your_Own_Bootloader
                bootloader UEFI app: https://wiki.osdev.org/UEFI_App_Bare_Bones
                making a bootable disk: https://wiki.osdev.org/Bootable_Disk
                -->
                <h4><a href="https://wiki.osdev.org/Bare_Bones">Bare Bones</a></h4>
    
                <h5>How to launch the OS? ESP with bootloader+kernel</h5>
                <p>
                    When the computer starts (power button shorts two mainboard pins), the mainboard firmware, following the widespread <abbr title="Unified Extensible Firmware Interface">UEFI</abbr> standard initializes connected hardware and, for each storage device, looks for partitions (separately managed storage parts) that are <abbr title="Extensible Firmware Interface">EFI</abbr> System Partitions (ESP).<br> UEFI supports some MBR and GPT partition table schemes <sup><a href="https://en.wikipedia.org/wiki/UEFI#EFI_system_partition">[1]</a></sup>.
                    It contains bootloaders: .efi files made to hand control from the firmware to the OS kernel (central program in the OS, responsible for ressource allocation and system calls etc.). In some configurable order, UEFI tries launching bootloaders until one works. The bootloader
                    <ul>
                        <li>determines which partition to boot from</li>
                        <li>finds the kernel in the partition and loads it into memory</li>
                        <li>sets up the environment: stack allocation, protected mode</li>
                        <li>hands control to the kernel, passing any necessary parameters to it</li>
                    </ul>
                </p>
    
                <h5>Bare Bones bootloader (GRUB), gluecode and kernel</h5>
                <p><abbr title="GRand Unified Bootloader">GRUB</abbr> is a magic bootloader that does everything for me and follows the Multiboot Standard when finding and handing control to the kernel. This means the kernel 1. needs a multiboot header and 2. is left to set up the stack itself. This first kernel part is written in assembly, because compiled C already requires a stack to run.</p>
                <pre><code>/* boot.s: minimal assembly to launch the kernel,
    compiled using <abbr title="GNU Assembler">GAS</abbr> to boot.o
    <a href="https://wiki.osdev.org/Bare_Bones#Bootstrap_Assembly">Bare Bones Boostrap Assembly</a> includes detailed comments */
    .set ALIGN,    1&lt;&lt;0      
    .set MEMINFO,  1&lt;&lt;1      
    .set FLAGS,    ALIGN | MEMINFO 
    .set MAGIC,    0x1BADB002      
    .set CHECKSUM, -(MAGIC + FLAGS)
    
    .section .multiboot
    .align 4
    .long MAGIC
    .long FLAGS
    .long CHECKSUM
    
    .section .bss
    .align 16
    stack_bottom:
    .skip 16384 # 16 KiB
    stack_top:
    
    .section .text
    .global _start
    .type _start, @function
    _start:
        mov $stack_top, %esp
        call kernel_main
        cli
    1:	hlt
        jmp 1b
    .size _start, . - _start</code></pre>
                <p>The kernel in Bare Bones, written in C, only uses the VGA text mode buffer presumtively set up by GRUB to display text on the screen.<br>
                It does this without the C standard library, which is unavailable because it would require 1. system calls and dynamic linker support already implemented in the kernel, and 2. the linker and library available at runtime. This is called being in a Freestanding Environment as opposed to a Hosted Environment. Some header files, though, are part of the compiler, not the C standard library, so some data types, constants and macros are still available.</p>
                <p>To compile the kernel, a <abbr title="GNU Compiler Collection">GCC</abbr> cross compiler is used.</p>
                <p>
                    Intel integrated graphics driver: <a href="https://www.intel.com/content/www/us/en/docs/graphics-for-linux/developer-reference/1-0/kaby-lake.html">Intel Docs</a>
                </p>
            </details>

            <h4>Text editor</h4>
            <details>
                <summary>Initial thoughts towards C+OpenGL text editor</summary>
                <p>OpenGL is a language to talk to the GPU to efficiently produce graphical output. It's implemented by the graphics card vendors. <a href="https://learnopengl.com">How to use OpenGL</a></p>
                <p>
                    To open a window and handle input, talking to the OS is necessary. Possible to do manually, but using <a href="https://open.gl/context#GLFW">GLFW</a> here.
                </p>
                
                <p>main.c to get OpenGL working and test it</p>
                <pre><code>#define GLEW_STATIC
#include <GL/glew.h>
#include <GLFW/glfw3.h>
#include <stdio.h>

int main() {
    glfwInit();

    glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3);
    glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 2);
    glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);
    glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE);

    glfwWindowHint(GLFW_RESIZABLE, GL_FALSE);

    GLFWwindow* window = glfwCreateWindow(800, 600, "OpenGL", NULL, NULL);
    glfwMakeContextCurrent(window);

    glewExperimental = GL_TRUE;
    glewInit();

    // Testing only: output should print 1
    GLuint vertexBuffer;
    glGenBuffers(1, &vertexBuffer);
    printf("%u\n", vertexBuffer);
    
    while(!glfwWindowShouldClose(window))
    {
        glfwSwapBuffers(window);
        glfwPollEvents();
    }

    glfwTerminate();
    return 0;
}</code></pre>
                <p>
                    Convention says to put main.c into src/ of project folder and the compiled output into build/.    
                    Compiling with: <code>clang -I ./include/ src/main.c -L ./lib/ -lGLEW -lglfw3 -lGL -lGLU -lm -o build/main</code>
                </p>
                <p>Compiling freetype2 to render true type fonts. Compiled from source with <code>./configure --enable-static --disable-shared --with-png=yes CFLAGS="-static"</code> and <code>make</code>. Then adding the <code>-lpng -lz -lbrotlidec -lfreetype</code> compiler flags.</p>

                <h4>OpenGL</h4>

                <p>It forces a framework onto graphics. Rendering each frame in a scene, it goes through a given graphics pipeline, determining the shape, rasterizing it and calculating color. Programs for each step are called shaders, though they look equivalent to compute kernels operating on different data. Minimum two shaders must be user specified: 1. Vertex shader: operates on vertex data for each frame without altering the original geometry. Can also add or remove vertices. 2. Fragment shader: operates on pixels after all invisible vertices have been culled. Handles texture sampling and color mixing.</p>

                <h5><a href="https://learnopengl.com/Getting-started/Hello-Triangle">Vertex Input</a></h5>
                <p>vertices = array of numbers -1.0 to 1.0 (outside those bounds is discarded) later to be interpreted as series of x,y,z coordinates of points, usually points of a triangle.</p>
                <p>Vertex Buffer Objects (VBOs) help with sending the data to the GPU. Bufferse are generated using a function (which assings an ID too). One Buffer can be bound at any time to any buffer type so all functions manipulating that buffer type will apply to the bound buffer. eg: <code>glBufferData(buffer type, size, vertices, memory optimization)</code> applies to the buffer current bound to [buffer type]</p>
                <p>Shaders are compile at runtime.</p>
                <p>Shader program will make the still separate vertex- and fragment shaders work, linking their in- and outputs accordingly.</p>
                <p>After program creation, the separate shaders are not needed anymore. <code>glUseProgram([shaderProgram])</code> will make any following shader/render call use it.</p>

                <h5>Linking vertex attriutes</h5>
                <p>how to interpret the vertex input? for which location (specified in vertex shader) is the data? how many values? what type? what stride? start reading the buffer with an offset?</p>

                <h4>Editor design</h4>
                <ol>
                    <li>initial usage: ss [path]</li>
                    <li>Load file into RAM</li>
                    <li>Get character set</li>
                    <li>render glyph atlas</li>
                    <li>split text into words (line breaks)</li>
                    <li>write words that fit into the line (monospace). If word longer than line, split without hyphen</li>
                </ol>
            </details>

            <h4>Internet</h4>
            <details>
                <summary>Notes on internet layers</summary>
                <p>https://explained-from-first-principles.com/internet/#out-of-order-delivery</p>
                <p>
                    messages understood through the protocol<br>
                    handle unexpected response, ask for retransmission, time out if silent, maintain order of messages, account for latency.
                </p>
                <p>5 layers</p>
                <ol>
                    <li>
                        <p>link:<br>
                            addressing using MAC address within a network through ethernet, wifi, bluetooth protocols.</p>
                    </li>
                    <li>
                        <p>network layer<br>
                            uses ip address to connect between different networks through the Internet Protocol (IP). routers send error messages and other information about itself using ICMP (internet control message p)</p>
                    </li>
                    <li>
                        <p>transport layer<br>
                            os sending/receiving stuff to/from to processes running in the OS. uses port numbers to differentiate.<br>
                            can use transmission control p (TCP). pretends there is a direct connection (not packets). enumerates, buffers and confirms received messages to put into right order, retransmit or request retransmission if no confirmation was received. uses checksum for ensuring reliability. sender slows down if it gets no feedback. tcp handshake before actual payload transfer sets a random starting point for the enumeration, making it hard for randos to impersonate.<br>
                            user datagram p (UDP) fast, unreliable connectionless transport. only source, destination ports, length and checksum in header</p>
                    </li>
                    <li>
                        <p>Security layer</p>
                    </li>
                </ol>
            </details>

            <p>
                <a href="https://twitter.com/karpathy/status/1751350002281300461">Karpathys ideal blogging platform</a><br>
                <a href="https://stephango.com/file-over-app">file over app</a>
            </p>
            <p>
                "lazy payment" - unrealized costs become realized when someone pays transaction costs? optionally anonymously.<br>
                payment + PAYG<br>
                tor<br>
                interplanetary file system</p>
                discord<br>
                plausible analytics<br>
                atom/rss<br>
            </p>

            <p>"Digital gardens"<br>
                <a href="https://github.com/MaggieAppleton/digital-gardeners">https://github.com/MaggieAppleton/digital-gardeners</a><br>
                <a href="https://simonewebdesign.it/">https://simonewebdesign.it/</a>
            </p>
            <p>
                <a href="https://casual-effects.com/markdeep/">markdeep</a><br>
                <a href="https://powerdns.org/libh2o/">libh2o</a>
                <a href="https://powerdns.org/">PowerDNS.org with nice articles</a>
            </p>

            <ul>
                <li>CSS is the visual vocabulary for html</li>
                <li>Who knows what and how people want to edit. Best editor is a tool to build your own editor?</li>
                <li>The things I know appear so simple, so efficiently encoded. Like how to make rice. But trying to explain it in its entirety, I require painfully many words even approximate it. How to know?</li>
                <li>llms contain linguistic maps. they can draw the landscape for me if they know my maps too</li>
                <li>a language model that has not learned to answer questions tells stories</li>
            </ul>

            <p>Maybe merging physical and virtual world means replicating my room in the computer and the computer in the room. Most of the room is static -> low network load; focus on moving and important parts instead: Faces. Computer should compress data by "scanning" environment and face and storing/transmitting transformations to save space.</p>
            <ul>
                <li>Apple vision pro with persistent locations for windows</li>
                <li>Gaussian scattering to capture room</li>
            </ul>

        </article>
        <script src="scroll.js"></script>
    </main>
</body>
</html>
